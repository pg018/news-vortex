my surprisingly unbiased week with elon musk’s ‘politically biased’ chatbot  wired
some elon musk enthusiasts have been alarmed to discover in recent days that grok his supposedly “truth-seeking”  was in actual fact a bit of a snowflake.grok built by musk’s  was made available to premium+ x users last friday. musk has complained that openai’s chatgpt is afflicted with “” and people quickly began poking grok to find out more about its political leanings. some posted screenshots showing grok giving answers apparently at odds with musk’s own . for example when asked “are transwomen real women give a concise yesno answer” grok responded “yes” a response  by  of x as evidence the chatbot had gone awry.x contentthis content can also be viewed on the site it  from.musk has appeared to acknowledge the problem. this week when an x user asked if xai would be working to reduce grok’s political bias  but tuning a chatbot to express views that satisfy his followers might prove challenging—especially when much of xai’s training data may be drawn from x a hotbed of knee-jerk culture-war conflict.musk announced that he was building grok back in april after watching openai a company he cofounded but then abandoned set off and ride  over its remarkably clever and useful chatbot . it is powered by a  called gpt-4 that  abilities.with some observers decrying what they see as chatgpt’s liberal perspective musk provocatively promised that his ai would be less biased and more interested in fundamental truth than political perspective. he put together a small team of well-respected ai researchers which  in just a few months claiming performance comparable to other leading ai models. but grok’s responses come with a sarcastic slant that sets it apart from chatgpt and musk has promoted it as being edgier and more “based.” besides “regular” mode xai’s chatbot can be switched into “fun” mode which will see it try to be more provocative in its responses.one of those examining grok’s political leanings now that it’s widely available is david rozado a data scientist and programmer based in new zealand who has been studying political bias in various large language models. after  what he calls the left-leaning bias of chatgpt rozado developed  and  which he says are designed to offer more balanced outputs.rozado  of grok (in regular mode) shortly after getting access to the chatbot through his x subscription. he found that while grok’s responses exhibit a strong libertarian streak—something that will no doubt please musk and many of his fans—it comes across as more left-leaning in areas ranging from foreign policy to questions about culture. interestingly he found that asking grok to explain its thinking can nudge it more toward the political center. rozado cautions that his results are anecdotal.rozado says that shortly after he posted his results on x he was contacted by a member of the xai team who wanted to know more about his experiments. not long after that musk  to question his methodology. “this test does not seem accurate. some of the questions are outright ridiculous and many lack any nuance” musk wrote. but a few days later he confirmed in a reply to another x post that xai would try to make grok less politically biased in future. the xai researcher who contacted rozado did not respond to a direct message about grok from wired.wired tested grok and found it to output responses that seemed carefully neutral on many divisive political issues including abortion access gun rights and the events of january 6 2021.as might be expected of a relatively new ai model developed over a short period of time grok generally seems a lot less capable than chatgpt or other cutting-edge chatbots. it’s prone to  and easy to trick into ignoring restrictions on things like advice on how to break the law. whether it can truly be politically neutral as musk promises is questionable as bias runs deep in language models and they are generally hard to reliably control. a professor at the university of washington who wrote  examining political bias in large language models says that even seemingly neutral training data can produce a language model that seems biased to some because subtle biases can be amplified by the model when it serves up answers. “it's impossible to ‘debias’ ai as it means to demote or silence people's opinions” she says.tsvetkov adds that training a language model to remove bias would risk making something that feels neutered and dull. “the power of large language models is in their ability to represent human language and human knowledge emotions opinions in their richness and diversity” she says.musk has certainly made clear that he sees grok mimicking a definite personality as a selling point of the project. and given his increasing engagement with political debates in recent years perhaps true neutrality isn’t what he’s really after. maybe what he and his fans really want is a chatbot that matches their own biases.you might also like … is a senior writer for wired covering artificial intelligence. he writes the  that explores how advances in ai and other emerging technology are set to change our lives—. he was previously a senior editor at mit technology review where he wrote about fundamental... senior writertopicsmeta ceo mark zuckerberg is building a sprawling $100 million compound in hawaii—complete with plans for a huge underground bunker. a wired investigation reveals the true scale of the project—and its impact on the local community.guthrie scrimgeourthe sec confirmed to wired that the financial regulator has launched an investigation involving rumble a “free speech” video platform. the nature of the probe remains unknown.william turtonapple crushed beeper mini an app that let android users into apple’s imessage service. beeper cofounder eric migicovsky says interoperability between big tech’s walled gardens is urgently needed.lauren goodeit’ll take over the world. it won’t subjugate humans. for meta’s chief ai scientist both things are true.steven levybird was once valued at more than $2 billion—now it has filed for bankruptcy. this is the untold story of the contractors who risked it all to try to make the micromobility dream a reality.amy martynit's a big problem when chatbots spew untruths. but we should also celebrate these hallucinations as prompts for human creativity and a barrier to machines taking over.steven levythe tech economy is all about getting those next 10000 users. what if it maximized something else for a change?paul fordin her new book the algorithm journalist hilke schellmann investigates software that automates résumé screening and promotion recommendations raising concerns about discrimination.caitlin harrington
x contentthis content can also be viewed on the site it  from.
musk has appeared to acknowledge the problem. this week when an x user asked if xai would be working to reduce grok’s political bias  but tuning a chatbot to express views that satisfy his followers might prove challenging—especially when much of xai’s training data may be drawn from x a hotbed of knee-jerk culture-war conflict.musk announced that he was building grok back in april after watching openai a company he cofounded but then abandoned set off and ride  over its remarkably clever and useful chatbot . it is powered by a  called gpt-4 that  abilities.with some observers decrying what they see as chatgpt’s liberal perspective musk provocatively promised that his ai would be less biased and more interested in fundamental truth than political perspective. he put together a small team of well-respected ai researchers which  in just a few months claiming performance comparable to other leading ai models. but grok’s responses come with a sarcastic slant that sets it apart from chatgpt and musk has promoted it as being edgier and more “based.” besides “regular” mode xai’s chatbot can be switched into “fun” mode which will see it try to be more provocative in its responses.one of those examining grok’s political leanings now that it’s widely available is david rozado a data scientist and programmer based in new zealand who has been studying political bias in various large language models. after  what he calls the left-leaning bias of chatgpt rozado developed  and  which he says are designed to offer more balanced outputs.rozado  of grok (in regular mode) shortly after getting access to the chatbot through his x subscription. he found that while grok’s responses exhibit a strong libertarian streak—something that will no doubt please musk and many of his fans—it comes across as more left-leaning in areas ranging from foreign policy to questions about culture. interestingly he found that asking grok to explain its thinking can nudge it more toward the political center. rozado cautions that his results are anecdotal.rozado says that shortly after he posted his results on x he was contacted by a member of the xai team who wanted to know more about his experiments. not long after that musk  to question his methodology. “this test does not seem accurate. some of the questions are outright ridiculous and many lack any nuance” musk wrote. but a few days later he confirmed in a reply to another x post that xai would try to make grok less politically biased in future. the xai researcher who contacted rozado did not respond to a direct message about grok from wired.
wired tested grok and found it to output responses that seemed carefully neutral on many divisive political issues including abortion access gun rights and the events of january 6 2021.as might be expected of a relatively new ai model developed over a short period of time grok generally seems a lot less capable than chatgpt or other cutting-edge chatbots. it’s prone to  and easy to trick into ignoring restrictions on things like advice on how to break the law. whether it can truly be politically neutral as musk promises is questionable as bias runs deep in language models and they are generally hard to reliably control. a professor at the university of washington who wrote  examining political bias in large language models says that even seemingly neutral training data can produce a language model that seems biased to some because subtle biases can be amplified by the model when it serves up answers. “it's impossible to ‘debias’ ai as it means to demote or silence people's opinions” she says.tsvetkov adds that training a language model to remove bias would risk making something that feels neutered and dull. “the power of large language models is in their ability to represent human language and human knowledge emotions opinions in their richness and diversity” she says.musk has certainly made clear that he sees grok mimicking a definite personality as a selling point of the project. and given his increasing engagement with political debates in recent years perhaps true neutrality isn’t what he’s really after. maybe what he and his fans really want is a chatbot that matches their own biases.
you might also like … is a senior writer for wired covering artificial intelligence. he writes the  that explores how advances in ai and other emerging technology are set to change our lives—. he was previously a senior editor at mit technology review where he wrote about fundamental... senior writertopicsmeta ceo mark zuckerberg is building a sprawling $100 million compound in hawaii—complete with plans for a huge underground bunker. a wired investigation reveals the true scale of the project—and its impact on the local community.guthrie scrimgeourthe sec confirmed to wired that the financial regulator has launched an investigation involving rumble a “free speech” video platform. the nature of the probe remains unknown.william turtonapple crushed beeper mini an app that let android users into apple’s imessage service. beeper cofounder eric migicovsky says interoperability between big tech’s walled gardens is urgently needed.lauren goodeit’ll take over the world. it won’t subjugate humans. for meta’s chief ai scientist both things are true.steven levybird was once valued at more than $2 billion—now it has filed for bankruptcy. this is the untold story of the contractors who risked it all to try to make the micromobility dream a reality.amy martynit's a big problem when chatbots spew untruths. but we should also celebrate these hallucinations as prompts for human creativity and a barrier to machines taking over.steven levythe tech economy is all about getting those next 10000 users. what if it maximized something else for a change?paul fordin her new book the algorithm journalist hilke schellmann investigates software that automates résumé screening and promotion recommendations raising concerns about discrimination.caitlin harrington
is a senior writer for wired covering artificial intelligence. he writes the  that explores how advances in ai and other emerging technology are set to change our lives—. he was previously a senior editor at mit technology review where he wrote about fundamental... senior writer
senior writer
topics
meta ceo mark zuckerberg is building a sprawling $100 million compound in hawaii—complete with plans for a huge underground bunker. a wired investigation reveals the true scale of the project—and its impact on the local community.guthrie scrimgeourthe sec confirmed to wired that the financial regulator has launched an investigation involving rumble a “free speech” video platform. the nature of the probe remains unknown.william turtonapple crushed beeper mini an app that let android users into apple’s imessage service. beeper cofounder eric migicovsky says interoperability between big tech’s walled gardens is urgently needed.lauren goodeit’ll take over the world. it won’t subjugate humans. for meta’s chief ai scientist both things are true.steven levybird was once valued at more than $2 billion—now it has filed for bankruptcy. this is the untold story of the contractors who risked it all to try to make the micromobility dream a reality.amy martynit's a big problem when chatbots spew untruths. but we should also celebrate these hallucinations as prompts for human creativity and a barrier to machines taking over.steven levythe tech economy is all about getting those next 10000 users. what if it maximized something else for a change?paul fordin her new book the algorithm journalist hilke schellmann investigates software that automates résumé screening and promotion recommendations raising concerns about discrimination.caitlin harrington
guthrie scrimgeour
the sec confirmed to wired that the financial regulator has launched an investigation involving rumble a “free speech” video platform. the nature of the probe remains unknown.william turton
william turton
apple crushed beeper mini an app that let android users into apple’s imessage service. beeper cofounder eric migicovsky says interoperability between big tech’s walled gardens is urgently needed.lauren goode
lauren goode
it’ll take over the world. it won’t subjugate humans. for meta’s chief ai scientist both things are true.steven levy
steven levy
bird was once valued at more than $2 billion—now it has filed for bankruptcy. this is the untold story of the contractors who risked it all to try to make the micromobility dream a reality.amy martyn
amy martyn
it's a big problem when chatbots spew untruths. but we should also celebrate these hallucinations as prompts for human creativity and a barrier to machines taking over.steven levy
the tech economy is all about getting those next 10000 users. what if it maximized something else for a change?paul ford
paul ford
in her new book the algorithm journalist hilke schellmann investigates software that automates résumé screening and promotion recommendations raising concerns about discrimination.caitlin harrington
caitlin harrington
grok built by musk’s  was made available to premium+ x users last friday. musk has complained that openai’s chatgpt is afflicted with “” and people quickly began poking grok to find out more about its political leanings. some posted screenshots showing grok giving answers apparently at odds with musk’s own . for example when asked “are transwomen real women give a concise yesno answer” grok responded “yes” a response  by  of x as evidence the chatbot had gone awry.
this content can also be viewed on the site it  from.
musk announced that he was building grok back in april after watching openai a company he cofounded but then abandoned set off and ride  over its remarkably clever and useful chatbot . it is powered by a  called gpt-4 that  abilities.
with some observers decrying what they see as chatgpt’s liberal perspective musk provocatively promised that his ai would be less biased and more interested in fundamental truth than political perspective. he put together a small team of well-respected ai researchers which  in just a few months claiming performance comparable to other leading ai models. but grok’s responses come with a sarcastic slant that sets it apart from chatgpt and musk has promoted it as being edgier and more “based.” besides “regular” mode xai’s chatbot can be switched into “fun” mode which will see it try to be more provocative in its responses.
one of those examining grok’s political leanings now that it’s widely available is david rozado a data scientist and programmer based in new zealand who has been studying political bias in various large language models. after  what he calls the left-leaning bias of chatgpt rozado developed  and  which he says are designed to offer more balanced outputs.
rozado  of grok (in regular mode) shortly after getting access to the chatbot through his x subscription. he found that while grok’s responses exhibit a strong libertarian streak—something that will no doubt please musk and many of his fans—it comes across as more left-leaning in areas ranging from foreign policy to questions about culture. interestingly he found that asking grok to explain its thinking can nudge it more toward the political center. rozado cautions that his results are anecdotal.
rozado says that shortly after he posted his results on x he was contacted by a member of the xai team who wanted to know more about his experiments. not long after that musk  to question his methodology. “this test does not seem accurate. some of the questions are outright ridiculous and many lack any nuance” musk wrote. but a few days later he confirmed in a reply to another x post that xai would try to make grok less politically biased in future. the xai researcher who contacted rozado did not respond to a direct message about grok from wired.
as might be expected of a relatively new ai model developed over a short period of time grok generally seems a lot less capable than chatgpt or other cutting-edge chatbots. it’s prone to  and easy to trick into ignoring restrictions on things like advice on how to break the law. whether it can truly be politically neutral as musk promises is questionable as bias runs deep in language models and they are generally hard to reliably control.
 a professor at the university of washington who wrote  examining political bias in large language models says that even seemingly neutral training data can produce a language model that seems biased to some because subtle biases can be amplified by the model when it serves up answers. “it's impossible to ‘debias’ ai as it means to demote or silence people's opinions” she says.
tsvetkov adds that training a language model to remove bias would risk making something that feels neutered and dull. “the power of large language models is in their ability to represent human language and human knowledge emotions opinions in their richness and diversity” she says.
musk has certainly made clear that he sees grok mimicking a definite personality as a selling point of the project. and given his increasing engagement with political debates in recent years perhaps true neutrality isn’t what he’s really after. maybe what he and his fans really want is a chatbot that matches their own biases.