staying one step ahead of hackers when it comes to ai  wired
if you’ve been creeping around underground tech forums lately you might have seen s for a new program called wormgpt.the program is an ai-powered tool for cybercriminals to automate the creation of personalized phishing emails; although it sounds a bit like chatgpt wormgpt is not your friendly neighborhood ai.chatgpt launched in november 2022 and since then generative ai has taken the world by storm. but few consider how its sudden rise will shape the future of cybersecurity.in 2024 generative ai is poised to facilitate new kinds of transnational—and translingual—cybercrime. for instance much cybercrime is masterminded by underemployed men from countries with underdeveloped tech economies. that english is not the primary language in these countries has thwarted hackers’ ability to defraud those in english-speaking economies; most native english speakers can quickly identify phishing emails by their unidiomatic and ungrammatical language.but generative ai will change that. cybercriminals from around the world can now use chatbots like wormgpt to pen well-written personalized phishing emails. by learning from phishermen across the web chatbots can craft data-driven scams that are especially convincing and effective.in 2024 generative ai will make biometric hacking easier too. until now biometric authentication methods—fingerprints facial recognition voice recognition—have been difficult (and costly) to impersonate; it’s not easy to fake a fingerprint a face or a voice.ai however has made deepfaking much less costly. can’t impersonate your target’s voice? tell a chatbot to do it for you.and what will happen when hackers begin targeting chatbots themselves? generative ai is just that—generative; it creates things that weren’t there before. the basic scheme allows an opportunity for hackers to inject malware into the objects generated by chatbots. in 2024 anyone using ai to write code will need to make sure that output hasn’t been created or modified by a hacker.other bad actors will also begin taking control of chatbots in 2024. a central feature of the new wave of generative ai is its “unexplainability.” algorithms trained via machine learning can return surprising and unpredictable answers to our questions. even though people designed the algorithm we don’t know how it works.it seems natural then that future chatbots will act as oracles attempting to answer difficult ethical and religious questions. on  for instance you can pose questions to an artificially intelligent jesus. ironically it’s not difficult to imagine programs like this being created in bad faith. an app called krishna for example has already  and supporting india's ruling party. what's to stop con artists from demanding tithes or promoting criminal acts? or as one chatbot has done telling users to leave their spouses?all security tools are dual-use—they can be used to attack or to defend—so in 2024 we should expect ai to be used for both offense and defense. hackers can use ai to fool facial recognition systems but developers can use ai to make their systems more secure. indeed machine learning has been used for over a decade to protect digital systems. before we get too worried about new ai attacks we should remember that there will also be new ai defenses to match.you might also like … is the founding director of the .contributortopicsrose-tinted predictions for artificial intelligence’s grand achievements will be swept aside by underwhelming performance and dangerous results.daron acemoglustepping off the hedonistic treadmill younger workers are demanding a more authentic employment experience.michèle lamontcrispr recently marked a major milestone in medicine. but it's not time for a victory lap—the race is just beginning.jennifer doudnaonline trust will reach an all-time low thanks to unchecked disinformation ai-generated content and social platforms pulling up their data drawbridges.gina neffmedicines need to be safe for all but also effective for the individual. embracing our differences will lead to better health care for everyone.angela sainiai chatbots can be friendly and responsive—even sexy. it’s time to take these fundamentally human behaviors more seriously.kate darlingthe pushback against ubiquitous surveillance and targeted deepfaking has begun—but regulation may fail to keep up with ai advances.joy buolamwinithe tech economy is all about getting those next 10000 users. what if it maximized something else for a change?paul ford
you might also like … is the founding director of the .contributortopicsrose-tinted predictions for artificial intelligence’s grand achievements will be swept aside by underwhelming performance and dangerous results.daron acemoglustepping off the hedonistic treadmill younger workers are demanding a more authentic employment experience.michèle lamontcrispr recently marked a major milestone in medicine. but it's not time for a victory lap—the race is just beginning.jennifer doudnaonline trust will reach an all-time low thanks to unchecked disinformation ai-generated content and social platforms pulling up their data drawbridges.gina neffmedicines need to be safe for all but also effective for the individual. embracing our differences will lead to better health care for everyone.angela sainiai chatbots can be friendly and responsive—even sexy. it’s time to take these fundamentally human behaviors more seriously.kate darlingthe pushback against ubiquitous surveillance and targeted deepfaking has begun—but regulation may fail to keep up with ai advances.joy buolamwinithe tech economy is all about getting those next 10000 users. what if it maximized something else for a change?paul ford
is the founding director of the .contributor
contributor
topics
rose-tinted predictions for artificial intelligence’s grand achievements will be swept aside by underwhelming performance and dangerous results.daron acemoglustepping off the hedonistic treadmill younger workers are demanding a more authentic employment experience.michèle lamontcrispr recently marked a major milestone in medicine. but it's not time for a victory lap—the race is just beginning.jennifer doudnaonline trust will reach an all-time low thanks to unchecked disinformation ai-generated content and social platforms pulling up their data drawbridges.gina neffmedicines need to be safe for all but also effective for the individual. embracing our differences will lead to better health care for everyone.angela sainiai chatbots can be friendly and responsive—even sexy. it’s time to take these fundamentally human behaviors more seriously.kate darlingthe pushback against ubiquitous surveillance and targeted deepfaking has begun—but regulation may fail to keep up with ai advances.joy buolamwinithe tech economy is all about getting those next 10000 users. what if it maximized something else for a change?paul ford
daron acemoglu
stepping off the hedonistic treadmill younger workers are demanding a more authentic employment experience.michèle lamont
michèle lamont
crispr recently marked a major milestone in medicine. but it's not time for a victory lap—the race is just beginning.jennifer doudna
jennifer doudna
online trust will reach an all-time low thanks to unchecked disinformation ai-generated content and social platforms pulling up their data drawbridges.gina neff
gina neff
medicines need to be safe for all but also effective for the individual. embracing our differences will lead to better health care for everyone.angela saini
angela saini
ai chatbots can be friendly and responsive—even sexy. it’s time to take these fundamentally human behaviors more seriously.kate darling
kate darling
the pushback against ubiquitous surveillance and targeted deepfaking has begun—but regulation may fail to keep up with ai advances.joy buolamwini
joy buolamwini
the tech economy is all about getting those next 10000 users. what if it maximized something else for a change?paul ford
paul ford
the program is an ai-powered tool for cybercriminals to automate the creation of personalized phishing emails; although it sounds a bit like chatgpt wormgpt is not your friendly neighborhood ai.
chatgpt launched in november 2022 and since then generative ai has taken the world by storm. but few consider how its sudden rise will shape the future of cybersecurity.
in 2024 generative ai is poised to facilitate new kinds of transnational—and translingual—cybercrime. for instance much cybercrime is masterminded by underemployed men from countries with underdeveloped tech economies. that english is not the primary language in these countries has thwarted hackers’ ability to defraud those in english-speaking economies; most native english speakers can quickly identify phishing emails by their unidiomatic and ungrammatical language.
but generative ai will change that. cybercriminals from around the world can now use chatbots like wormgpt to pen well-written personalized phishing emails. by learning from phishermen across the web chatbots can craft data-driven scams that are especially convincing and effective.
in 2024 generative ai will make biometric hacking easier too. until now biometric authentication methods—fingerprints facial recognition voice recognition—have been difficult (and costly) to impersonate; it’s not easy to fake a fingerprint a face or a voice.
ai however has made deepfaking much less costly. can’t impersonate your target’s voice? tell a chatbot to do it for you.
and what will happen when hackers begin targeting chatbots themselves? generative ai is just that—generative; it creates things that weren’t there before. the basic scheme allows an opportunity for hackers to inject malware into the objects generated by chatbots. in 2024 anyone using ai to write code will need to make sure that output hasn’t been created or modified by a hacker.
other bad actors will also begin taking control of chatbots in 2024. a central feature of the new wave of generative ai is its “unexplainability.” algorithms trained via machine learning can return surprising and unpredictable answers to our questions. even though people designed the algorithm we don’t know how it works.
it seems natural then that future chatbots will act as oracles attempting to answer difficult ethical and religious questions. on  for instance you can pose questions to an artificially intelligent jesus. ironically it’s not difficult to imagine programs like this being created in bad faith. an app called krishna for example has already  and supporting india's ruling party. what's to stop con artists from demanding tithes or promoting criminal acts? or as one chatbot has done telling users to leave their spouses?
all security tools are dual-use—they can be used to attack or to defend—so in 2024 we should expect ai to be used for both offense and defense. hackers can use ai to fool facial recognition systems but developers can use ai to make their systems more secure. indeed machine learning has been used for over a decade to protect digital systems. before we get too worried about new ai attacks we should remember that there will also be new ai defenses to match.