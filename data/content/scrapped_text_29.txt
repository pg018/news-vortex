how to check if something online was written by ai
the future is hereit's tricky but not impossible to figure out if something wasn't written by a human.by.generative artificial intelligence is  these days including on the web advanced predictive text bots such as chatgpt can now spew out endless reams of text on every topic imaginable and make all this written content natural enough that it could plausibly have been written by a human being.watchzillow says you’ll buy your next house with… ai?  ai unlocked
so how can you make sure the articles and features you’re reading online have been thought up and typed out by an actual human being? while there isn’t any foolproof 100 percent guaranteed way of doing this there are a variety of clues you can look out for to spot what’s ai-generated and what isn’t.check the authorfor now at least there aren’t any high-profile well-respected online outlets pumping out ai content without labeling it as such—but there are plenty of lower-tier sites making full use of ai-generated text and not being particularly honest about it. if you’re coming across a lot of text without author attribution that’s one warning sign to look out for.in contrast if an article has the name of a real person attached—even better a real person with a bio and social media links—then you’re more likely to be reading something that has been put together by a human. you’ll probably not have time to background check everything you read online but it’s worth it when you really need to know its source.the alleged ai articles  on the sports illustrated site came with author profiles and bios alongside them—profiles and bios that were also made by generative ai it turns out. a reverse image search (through something like ) can identify images of people that aren’t actually real which might be helpful in determining an article’s source.more clues can be gleaned from a website in terms of its history the type of content it publishes whether or not it has an about us page and so on. for example searching for the best phone reviews on the web brings up well-known tech sites staffed by human beings.check a detection enginethere’s plenty of debate about whether or not ai text detection works. openai  and  on the matter says these ai detectors aren’t to be trusted. however there are still plenty of them in business at the time of writing and within limits they might be useful in checking for the use of ai online.we ran a brief series of tests on a few ai detectors online including   and  and what we found tallies with what other people have found these detectors can tell the difference between ai writing and human writing but not all the time and not to a level that conclusively proves anything one way or another.these detectors seem to have a better success rate at spotting human writing than ai writing. they’re essentially looking for originality in the text trying to figure out what an ai would say next based on its training. the more data they have to work with the better but there are limits on how much you can use for free.the studies  to date suggest that some detectors are better than others and that some are even right most of the time—but none of them are consistently right to a high level. these detectors are perhaps best thought of as another tool you can use alongside other avenues of inquiry and not something to rely on entirely.check the signsas we said at the start there’s really no guaranteed way of identifying which online text has been produced by ai and which hasn’t. however there are still certain signs to look out for because of the way generative ai is trained its output tends to be generic vague and obvious at times.certain touches of originality humor and humanity are often missing (as are personal anecdotes). ai always wants to generate text that has —put another way a high level of predictability. at their heart these engines are just predicting what word should come next and that can show in a general mushiness and blandness that is sometimes noticeable.you can also look out for glaring errors () but of course human beings make errors in their writing too. ai text might be capable of getting something significantly wrong or significantly wrong multiple times in different ways but it still doesn’t prove if ai has composed an article.taking all these signals and clues and flags together you may just be able to make an educated guess about whether something came from a human mind or not even if the only way to be sure is to watch it being written ai text is certainly harder to spot than ai imagery but that’s a whole other topic.
it's tricky but not impossible to figure out if something wasn't written by a human.
by.generative artificial intelligence is  these days including on the web advanced predictive text bots such as chatgpt can now spew out endless reams of text on every topic imaginable and make all this written content natural enough that it could plausibly have been written by a human being.watchzillow says you’ll buy your next house with… ai?  ai unlocked
generative artificial intelligence is  these days including on the web advanced predictive text bots such as chatgpt can now spew out endless reams of text on every topic imaginable and make all this written content natural enough that it could plausibly have been written by a human being.watchzillow says you’ll buy your next house with… ai?  ai unlocked
watchzillow says you’ll buy your next house with… ai?  ai unlocked
zillow says you’ll buy your next house with… ai?  ai unlocked
share
subtitles
for now at least there aren’t any high-profile well-respected online outlets pumping out ai content without labeling it as such—but there are plenty of lower-tier sites making full use of ai-generated text and not being particularly honest about it. if you’re coming across a lot of text without author attribution that’s one warning sign to look out for.
in contrast if an article has the name of a real person attached—even better a real person with a bio and social media links—then you’re more likely to be reading something that has been put together by a human. you’ll probably not have time to background check everything you read online but it’s worth it when you really need to know its source.
the alleged ai articles  on the sports illustrated site came with author profiles and bios alongside them—profiles and bios that were also made by generative ai it turns out. a reverse image search (through something like ) can identify images of people that aren’t actually real which might be helpful in determining an article’s source.
more clues can be gleaned from a website in terms of its history the type of content it publishes whether or not it has an about us page and so on. for example searching for the best phone reviews on the web brings up well-known tech sites staffed by human beings.
there’s plenty of debate about whether or not ai text detection works. openai  and  on the matter says these ai detectors aren’t to be trusted. however there are still plenty of them in business at the time of writing and within limits they might be useful in checking for the use of ai online.
we ran a brief series of tests on a few ai detectors online including   and  and what we found tallies with what other people have found these detectors can tell the difference between ai writing and human writing but not all the time and not to a level that conclusively proves anything one way or another.
these detectors seem to have a better success rate at spotting human writing than ai writing. they’re essentially looking for originality in the text trying to figure out what an ai would say next based on its training. the more data they have to work with the better but there are limits on how much you can use for free.
the studies  to date suggest that some detectors are better than others and that some are even right most of the time—but none of them are consistently right to a high level. these detectors are perhaps best thought of as another tool you can use alongside other avenues of inquiry and not something to rely on entirely.
as we said at the start there’s really no guaranteed way of identifying which online text has been produced by ai and which hasn’t. however there are still certain signs to look out for because of the way generative ai is trained its output tends to be generic vague and obvious at times.
certain touches of originality humor and humanity are often missing (as are personal anecdotes). ai always wants to generate text that has —put another way a high level of predictability. at their heart these engines are just predicting what word should come next and that can show in a general mushiness and blandness that is sometimes noticeable.
you can also look out for glaring errors () but of course human beings make errors in their writing too. ai text might be capable of getting something significantly wrong or significantly wrong multiple times in different ways but it still doesn’t prove if ai has composed an article.
taking all these signals and clues and flags together you may just be able to make an educated guess about whether something came from a human mind or not even if the only way to be sure is to watch it being written ai text is certainly harder to spot than ai imagery but that’s a whole other topic.